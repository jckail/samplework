import pandas as pd
from os.path import basename
from os import stat
from pwd import getpwuid
import os
import os.path, time
from sqlalchemy import create_engine
import psycopg2

connection_url = 'your connection url'
conn = psycopg2.connect("your connection url")
SQL_STATEMENT = """
    COPY %s FROM STDIN WITH
        CSV
        HEADER
        DELIMITER AS ','
    """

def creation_date(path_to_file):
    return time.ctime(os.path.getctime(path_to_file))

def modify_date(path_to_file):
    return time.ctime(os.path.getmtime(path_to_file))

def find_owner(filename):
    return getpwuid(stat(filename).st_uid).pw_name

input_directory = 'your directory here'
master_table = pd.DataFrame(None)

def get_files(input_directory):
    dir_list = []
    for file in os.listdir(input_directory):
        if file.endswith(".csv") :
            path = os.path.join(input_directory, file)
            dir_list.append(path)
    return dir_list

def file_data_frame_gen (file):
    frame = pd.read_csv(file)

    #print frame
    return frame


def main():
    dir_list = get_files(input_directory)
    for file in dir_list:
        print file
        file_name = basename(file.replace(".csv",""))
        file_name = basename(file_name.replace(".json",""))
        file_name =  file_name.replace(" ","")
        file_name =  file_name.replace("_","")
        table_name = file_name

        file_df = file_data_frame_gen(file)
        #this will work on a better* computer?

        engine = create_engine(connection_url)
        #print file_df
        headers = file_df.head(0)
        headers.to_sql(table_name, engine, if_exists ='replace', chunksize= 10, index= False)
        print table_name + ' created!'
        #this is a truncate and reload process
        #file_df.to_sql(table_name, engine, if_exists ='replace') data frame to table write is too slow
        cur = conn.cursor()
        f = open(file, 'r')
        cur.copy_expert(sql=SQL_STATEMENT % table_name, file= f)
        query = """select count(*) from database.schema.%s """
        cur.execute(query % table_name)
        conn.commit()
        f.close()
        print str(cur.fetchone()[0]) + " Records Inserted"

main()